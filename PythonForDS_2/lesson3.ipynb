{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы\n",
    "## Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?\n",
    "**Ответ:** \n",
    "1. **micro** - используется для оценки метрик в несбалансироанных данных в которых не важна разница весов классов. \n",
    "2. **macro** - простое арифмитическое среднее между f1-оценками разных классов. Общая оценка модели.\n",
    "3. **weighted** - расчет метрики с учетом весов каждого класса (их численности). Оценка несбалансированной модели в которой важна разница весов классов.\n",
    "\n",
    "## В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?\n",
    "**Ответ:** \n",
    "1. **xgboost** - давольно старый алгоритм, работает медненно, но точно. Не работает с категориальными данными.\n",
    "2. **lightgbm** - новая модель, способная принимать категориальные данные, но только в числовом формате. Работает быстро, но не идеально.\n",
    "3. **catboost** - новейшая модель, способна принимать категориальные данные, как в числовом, так и в строковом формате. Работает давольно быстро, если правильно настроена, результаты сравнимы с xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение моделей классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание датасета \n",
    "**подпункты с описанием добавленных столбцов после подготовки**\n",
    "\n",
    "\n",
    "* **Home Ownership** - домовладение\n",
    "        \n",
    "        1. разложен на дамми переменные\n",
    "    \n",
    "* **Annual Income** - годовой доход\n",
    "        \n",
    "        1. Annual Income upd.2 - пропуски заполены мединой\n",
    "        2. Annual Income upd.3 - пропуски заполнены моделью (близжайшие соседи)\n",
    "        \n",
    "* **Years in current job** - количество лет на текущем месте работы\n",
    "\n",
    "        1. upd2 - замененные на числовые значения и заполненные модой\n",
    "        2. дамми переменные заполненные модой\n",
    "        3. upd.3 - пропуски заполнены моделью (близжайшие соседи)\n",
    "        \n",
    "* **Tax Liens** - налоговые обременения\n",
    "* **Number of Open Accounts** - количество открытых счетов\n",
    "* **Years of Credit History** - количество лет кредитной истории\n",
    "* **Maximum Open Credit** - наибольший открытый кредит\n",
    "* **Number of Credit Problems** - количество проблем с кредитом\n",
    "* **Months since last delinquent** - количество месяцев с последней просрочки платежа\n",
    "* **Bankruptcies** - банкротства\n",
    "        \n",
    "        1. upd.2 - пропуски заполены модой\n",
    "        2. upd.3 - пропуски заполнены моделью (близжайшие соседи)\n",
    "        \n",
    "* **Purpose** - цель кредита\n",
    "        \n",
    "        1. разложен на дамми переменные\n",
    "  \n",
    "* **Term** - срок кредита\n",
    "        \n",
    "        1. разложен на дамми переменные\n",
    "  \n",
    "* **Current Loan Amount** - текущая сумма кредита\n",
    "        \n",
    "        1. ver.2 - выбросы заполены регрессией\n",
    "        \n",
    "* **Current Credit Balance** - текущий кредитный баланс\n",
    "* **Monthly Debt** - ежемесячный долг\n",
    "* **Credit Default** - факт невыполнения кредитных обязательств (0 - погашен вовремя, 1 - просрочка)\n",
    "* **Credit Score** - кредитные очки\n",
    "        \n",
    "        1. ver.2 - убраны выбросы и заполнены пропуски с помощью модели\n",
    "        2. ver.3 - убраны выбросы и заполнены пропуски медианой\n",
    "        3. ver.4 - убраны выбросы и пропуски заполнены моделью (близжайшие соседи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание групп признаков\n",
    "\n",
    "* TARGET_NAME - целевая переменная\n",
    "* full_features_list - все признаки без пропусков\n",
    "* num_features - числовые признаки\n",
    "* cat_features_str - категориальные признаки (со стороквыми для **CatBoost**)\n",
    "* cat_features_dumm_years_dummy - категориальные признаки разбитые на дамми переменные где \"Years in current job\" тоже разбит\n",
    "* cat_features_dumm_years_one - категориальные признаки разбитые на дамми переменные где \"Years in current job\" заменен на числовые значения\n",
    "* cat_features_str_to_int - категориальные признаки (где значения заменены на цифры для **LightGBM**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COURSE_PROJECT_DATASET_TRAIN_PREP = 'course_project/course_project_train_prep.csv'\n",
    "PATH_COURSE_PROJECT_DATASET_TRAIN = 'course_project/course_project_train.csv'\n",
    "\n",
    "PATH_COURSE_PROJECT_DATASET_TEST_PREP = 'course_project/course_project_test_prep.csv'\n",
    "PATH_COURSE_PROJECT_DATASET_TEST = 'course_project/course_project_test.csv'\n",
    "\n",
    "SCALER_FILE_PATH = 'scaler.pkl'\n",
    "\n",
    "TRAIN_FULL_PATH = 'course_project_train_full.csv'\n",
    "TRAIN_PART_PATH = 'course_project_train_part.csv'\n",
    "TEST_PART_PATH = 'course_project_test_part.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем базы данных\n",
    "Чистим от не нужных столбцов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(PATH_COURSE_PROJECT_DATASET_TRAIN)\n",
    "\n",
    "df_new = pd.read_csv(PATH_COURSE_PROJECT_DATASET_TRAIN_PREP)\n",
    "df_new.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "df_test_base = pd.read_csv(PATH_COURSE_PROJECT_DATASET_TEST)\n",
    "df_test_new = pd.read_csv(PATH_COURSE_PROJECT_DATASET_TEST_PREP)\n",
    "df_test_new.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['NEW_2_C-P'] = df_new['NEW_2_C-P'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразуем строковые значения категориальных признаков в числовые для модели LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [df_new, df_test_new]\n",
    "for cat in df_new.select_dtypes(include='object').columns.drop('Years in current job'):\n",
    "    dict_of_values_name = dict()\n",
    "    repeat_number = 0\n",
    "    for dataset in dataset_list:\n",
    "        n = 0\n",
    "        dataset[f'{cat}_for_LGBM'] = dataset[cat].copy()\n",
    "        for value_name in dataset[f'{cat}_for_LGBM'].value_counts().index:\n",
    "            if repeat_number == 0:\n",
    "                dataset[f'{cat}_for_LGBM'].loc[dataset[f'{cat}_for_LGBM'] == value_name] = n\n",
    "                dict_of_values_name[value_name] = n\n",
    "                n += 1\n",
    "            if repeat_number == 1:\n",
    "                try:\n",
    "                    dataset[f'{cat}_for_LGBM'].loc[dataset[f'{cat}_for_LGBM'] == value_name] = dict_of_values_name[value_name]\n",
    "                except Exception as e:\n",
    "                    dataset[f'{cat}_for_LGBM'].loc[dataset[f'{cat}_for_LGBM'] == value_name] = dict_of_values_name['other']  \n",
    "        dataset[f'{cat}_for_LGBM'] = dataset[f'{cat}_for_LGBM'].astype('int64')\n",
    "    repeat_number +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Округляем значения Credit Score ver.2 для возможного использования признака как категориального"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Credit Score ver.2'] = round(df_new['Credit Score ver.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Длинна позволяет (до 255)\n",
    "len(df_new['Credit Score ver.2'].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем соответствие тествого и тренеровочного датасетов по признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fearures_list = df_test_new.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Default\n"
     ]
    }
   ],
   "source": [
    "new_fearures_list = df_test_new.columns.tolist()\n",
    "for i in df_new.columns.tolist():\n",
    "    try:\n",
    "        new_fearures_list.remove(i)\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "new_fearures_list = df_new.columns.tolist()\n",
    "for i in df_test_new.columns.tolist():\n",
    "    try:\n",
    "        new_fearures_list.remove(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распределяем признаки по моделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'Credit Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_features_list = [col for col in df_new.columns.tolist() if df_new[col].isnull().sum() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тест без признака number open accounts\n",
    "full_features_list.remove('Number of Open Accounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df_new[full_features_list].select_dtypes(include=['float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['pca_1_H-O_OH_R', 'pca_2_H-O_OH_R', 'Credit Score ver.3', 'Annual Income upd.2', 'Current Loan Amount']:\n",
    "    num_features.remove(i)\n",
    "    \n",
    "for i in ['Credit Score ver.2', 'Bankruptcies upd.2']:\n",
    "    num_features.remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tax Liens',\n",
       " 'Years of Credit History',\n",
       " 'Maximum Open Credit',\n",
       " 'Number of Credit Problems',\n",
       " 'Current Credit Balance',\n",
       " 'Monthly Debt',\n",
       " 'Current Loan Amount ver.2',\n",
       " 'Annual Income upd.3',\n",
       " 'Credit Score ver.4',\n",
       " 'Bankruptcies upd.3',\n",
       " 'Years in current job upd.3']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Purpose', 'Term', 'NEW_1_H-O']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_str = df_new[full_features_list].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "cat_features_str.append('NEW_1_H-O')\n",
    "cat_features_str.remove('Home Ownership')\n",
    "cat_features_str.remove('Years in current job')\n",
    "cat_features_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_features_dumm_years_dummy = df_new[full_features_list].drop(TARGET_NAME, axis=1).select_dtypes(include=['int']).columns.tolist()[:-3]\n",
    "cat_features_dumm_years_one = cat_features_dumm_years_dummy[:-10]\n",
    "cat_features_dumm_years_dummy.remove('Years in current job upd.2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_str_to_int = full_features_list[-3:]\n",
    "cat_features_str_to_int.append('Years in current job upd.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categorical_features = cat_features_str_to_int + cat_features_str + cat_features_dumm_years_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_features_list = num_features + all_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home Ownership_for_LGBM',\n",
       " 'Purpose_for_LGBM',\n",
       " 'Term_for_LGBM',\n",
       " 'Years in current job upd.2']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_str_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приведение типов для модели  CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in cat_features_str:\n",
    "    df_new[colname] = pd.Categorical(df_new[colname])\n",
    "    \n",
    "df_new[cat_features_str].dtypes\n",
    "\n",
    "catB_features = num_features + cat_features_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features2 = num_features.copy()\n",
    "# num_features2.remove('Credit Score ver.2')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_norm = df_new.copy()\n",
    "df_norm[num_features2] = scaler.fit_transform(df_norm[num_features2])\n",
    "\n",
    "df_new = df_norm.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохранение модели для нормализации данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCALER_FILE_PATH, 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_new[ready_features_list]\n",
    "# y = df_new[TARGET_NAME]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "catB_features = list(set(catB_features))\n",
    "all_categorical_features = list(set(all_categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_features_list = list(set(ready_features_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=[df_new[ready_features_list].columns.get_loc(col) for col in all_categorical_features], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new[ready_features_list]\n",
    "y = df_new[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 1467\n",
      "Before OverSampling, counts of label '0': 3783 \n",
      "\n",
      "After OverSampling, the shape of X_train: (7566, 47)\n",
      "After OverSampling, the shape of y_train: (7566,) \n",
      "\n",
      "After OverSampling, counts of label '1': 3783\n",
      "After OverSampling, counts of label '0': 3783\n"
     ]
    }
   ],
   "source": [
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "print(f\"Before OverSampling, counts of label '1': {sum(y_train==1)}\")\n",
    "print(f\"Before OverSampling, counts of label '0': {sum(y_train==0)} \\n\")\n",
    "print(f'After OverSampling, the shape of X_train: {X_train_res.shape}')\n",
    "print(f'After OverSampling, the shape of y_train: {y_train_res.shape} \\n')\n",
    "print(f\"After OverSampling, counts of label '1': {sum(y_train_res==1)}\")\n",
    "print(f\"After OverSampling, counts of label '0': {sum(y_train_res==0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение обучающего и тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train_res, y_train_res], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(TRAIN_FULL_PATH, index=False, encoding='utf-8')\n",
    "train.to_csv(TRAIN_PART_PATH, index=False, encoding='utf-8')\n",
    "test.to_csv(TEST_PART_PATH, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение и оценка бозовых моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65      3783\n",
      "           1       0.64      0.56      0.60      3783\n",
      "\n",
      "    accuracy                           0.62      7566\n",
      "   macro avg       0.63      0.62      0.62      7566\n",
      "weighted avg       0.63      0.62      0.62      7566\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73      1604\n",
      "           1       0.40      0.52      0.45       646\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.59      0.60      0.59      2250\n",
      "weighted avg       0.67      0.64      0.65      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1107  497\n",
      "1                311  335\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_res[cat_features_dumm_years_one + num_features], y_train_res)\n",
    "\n",
    "y_train_pred = model_lr.predict(X_train_res[cat_features_dumm_years_one + num_features])\n",
    "y_test_pred = model_lr.predict(X_test[cat_features_dumm_years_one + num_features])\n",
    "\n",
    "get_classification_report(y_train_res, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      3783\n",
      "           1       0.77      0.90      0.83      3783\n",
      "\n",
      "    accuracy                           0.82      7566\n",
      "   macro avg       0.83      0.82      0.82      7566\n",
      "weighted avg       0.83      0.82      0.82      7566\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67      1604\n",
      "           1       0.33      0.49      0.39       646\n",
      "\n",
      "    accuracy                           0.57      2250\n",
      "   macro avg       0.54      0.55      0.53      2250\n",
      "weighted avg       0.63      0.57      0.59      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               972  632\n",
      "1               332  314\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train_res[cat_features_dumm_years_one + num_features], y_train_res)\n",
    "\n",
    "y_train_pred = model_knn.predict(X_train_res[cat_features_dumm_years_one + num_features])\n",
    "y_test_pred = model_knn.predict(X_test[cat_features_dumm_years_one + num_features])\n",
    "\n",
    "get_classification_report(y_train_res, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      3783\n",
      "           1       0.96      0.95      0.95      3783\n",
      "\n",
      "    accuracy                           0.95      7566\n",
      "   macro avg       0.95      0.95      0.95      7566\n",
      "weighted avg       0.95      0.95      0.95      7566\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67      1604\n",
      "           1       0.33      0.49      0.39       646\n",
      "\n",
      "    accuracy                           0.57      2250\n",
      "   macro avg       0.54      0.55      0.53      2250\n",
      "weighted avg       0.63      0.57      0.59      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               972  632\n",
      "1               332  314\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier()\n",
    "model_xgb.fit(X_train_res[cat_features_dumm_years_one + num_features], y_train_res)\n",
    "\n",
    "y_train_pred = model_xgb.predict(X_train_res[cat_features_dumm_years_one + num_features])\n",
    "y_test_pred = model_knn.predict(X_test[cat_features_dumm_years_one + num_features])\n",
    "\n",
    "get_classification_report(y_train_res, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      3783\n",
      "           1       0.88      0.88      0.88      3783\n",
      "\n",
      "    accuracy                           0.88      7566\n",
      "   macro avg       0.88      0.88      0.88      7566\n",
      "weighted avg       0.88      0.88      0.88      7566\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1604\n",
      "           1       0.41      0.42      0.41       646\n",
      "\n",
      "    accuracy                           0.66      2250\n",
      "   macro avg       0.58      0.59      0.59      2250\n",
      "weighted avg       0.66      0.66      0.66      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1205  399\n",
      "1                374  272\n"
     ]
    }
   ],
   "source": [
    "model_lgbm = lgbm.LGBMClassifier()\n",
    "model_lgbm.fit(X_train_res[num_features + cat_features_str_to_int], y_train_res, categorical_feature=[df_new[num_features + cat_features_str_to_int].columns.get_loc(col) for col in cat_features_str_to_int])\n",
    "\n",
    "y_train_pred = model_lgbm.predict(X_train_res[num_features + cat_features_str_to_int])\n",
    "y_test_pred = model_lgbm.predict(X_test[num_features + cat_features_str_to_int])\n",
    "\n",
    "get_classification_report(y_train_res, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_features = num_features + cat_features_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69      3783\n",
      "           1       0.68      0.78      0.73      3783\n",
      "\n",
      "    accuracy                           0.71      7566\n",
      "   macro avg       0.71      0.71      0.71      7566\n",
      "weighted avg       0.71      0.71      0.71      7566\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70      1604\n",
      "           1       0.39      0.60      0.47       646\n",
      "\n",
      "    accuracy                           0.62      2250\n",
      "   macro avg       0.59      0.61      0.58      2250\n",
      "weighted avg       0.68      0.62      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               999  605\n",
      "1               260  386\n",
      "CPU times: user 5.99 s, sys: 775 ms, total: 6.77 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_catb = catb.CatBoostClassifier(silent=True, \n",
    "                                     n_estimators=500,\n",
    "#                                      one_hot_max_size=10, \n",
    "#                                      learning_rate=0.5, \n",
    "                                     l2_leaf_reg=10, \n",
    "#                                      iterations=700,\n",
    "                                     depth=3,\n",
    "#                                      class_weights=[1, 1.8],\n",
    "                                     cat_features=cat_features_str)\n",
    "\n",
    "model_catb.fit(X_train_res[importance_features], y_train_res, cat_features=cat_features_str)\n",
    "\n",
    "y_train_pred = model_catb.predict(X_train_res[importance_features])\n",
    "y_test_pred = model_catb.predict(X_test[importance_features])\n",
    "\n",
    "get_classification_report(y_train_res, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bankruptcies upd.3             0.277631\n",
       "Tax Liens                      1.002112\n",
       "Number of Credit Problems      1.818746\n",
       "NEW_1_H-O                      2.515565\n",
       "Purpose                        2.702066\n",
       "Current Credit Balance         3.600171\n",
       "Current Loan Amount ver.2      4.545931\n",
       "Years of Credit History        4.703161\n",
       "Maximum Open Credit            4.703268\n",
       "Monthly Debt                   5.495501\n",
       "Term                           6.360676\n",
       "Years in current job upd.3    10.911732\n",
       "Annual Income upd.3           12.337932\n",
       "Credit Score ver.4            39.025508\n",
       "dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_catb.feature_importances_, index=model_catb.feature_names_).sort_values(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
